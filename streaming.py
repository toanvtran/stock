# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15munj4odu3ngFu0iOTe-L5XMrsgryO1e
"""

def fetch_ohlcv_data(symbol, interval='1m', limit=20):
    """
    Fetch historical OHLCV data from CryptoWatch.

    :param exchange: The exchange (e.g., 'binance')
    :param pair: The trading pair (e.g., 'btcusdt')
    :param period: The time period (e.g., 3600 for 1-hour)
    :param limit: The number of data points to fetch
    :return: List of OHLCV data (open, high, low, close, volume)
    """

    api_key = '1e177e4c-bc22-4b93-af52-a317d046880e'
    # Base URL for CoinCap API
    url = f'https://api.coincap.io/v2/assets'

    # Headers with authentication
    headers = {
        'Authorization': f'Bearer {api_key}'
    }

    # Send the GET request
    params = {
        'interval': interval,  # Time interval (1d, 1h, etc.)
        'limit': limit  # Number of data points to retrieve
    }
    response = requests.get(url, headers = headers, params=params)

    if response.status_code == 200:
        data = response.json()
        return data['data']
    else:
        print(f"Failed to fetch data from CoinCap for {symbol}: {response.status_code}")
        return []

import time, requests
from datetime import datetime
symbols = ['bitcoin']

while True:
  ohlcv_data = fetch_ohlcv_data(0)  # Fetch OHLCV data for each symbol

  for data in ohlcv_data:
      print(data)
      timestamp = datetime.now().isoformat()  # Convert timestamp to ISO format
      message = {
          'symbol': data['id'],
          'timestamp': timestamp,
          'rank': data['rank'],
          'priceUsd': data['priceUsd'],
          'marketCapUsd': data['marketCapUsd'],
          'volumeUsd24Hr': data['volumeUsd24Hr'],
          'changePercent24Hr': data['changePercent24Hr'],
          'vwap24Hr': data['vwap24Hr'],
          'supply': data['supply'],
          'maxSupply': data['maxSupply']
      }

      # Send the message to Kafka
      # producer.produce(TOPIC, key=symbol, value=json.dumps(message), callback=delivery_report)
      # producer.poll(0)  # Poll the producer for delivery events
      # print(f"Produced: {message}")

  time.sleep(60)  # Delay between fetching data (e.g., fetch every 60 seconds)

